#!/usr/bin/env python3
"""
–¢–µ—Å—Ç–∏—Ä–æ–≤–∞–Ω–∏–µ vLLM 0.11.0 –Ω–∞ —Å—Ç—Ä–∞–Ω–∏—Ü–µ 23 –¥–æ–∫—É–º–µ–Ω—Ç–∞ –î–ü-–ú1.020-06
–°—Ä–∞–≤–Ω–µ–Ω–∏–µ —Å —Ä–µ–∑—É–ª—å—Ç–∞—Ç–∞–º–∏ Transformers+flash_attn
"""

import os
import sys
import time
import torch
from pathlib import Path

# –ù–∞—Å—Ç—Ä–æ–π–∫–∏ –æ–∫—Ä—É–∂–µ–Ω–∏—è –¥–ª—è vLLM
os.environ["CUDA_VISIBLE_DEVICES"] = '0'

from vllm import LLM, SamplingParams
from PIL import Image, ImageOps

# –ò—Å–ø–æ–ª—å–∑—É–µ–º –≤—Å—Ç—Ä–æ–µ–Ω–Ω—ã–π –≤ vLLM 0.11.0 –ª–æ–≥–∏—Ç –ø—Ä–æ—Ü–µ—Å—Å–æ—Ä –¥–ª—è DeepSeek-OCR
NGramPerReqLogitsProcessor = None
try:
    from vllm.model_executor.models.deepseek_ocr import NGramPerReqLogitsProcessor
    print("‚úÖ –ò—Å–ø–æ–ª—å–∑—É–µ—Ç—Å—è –≤—Å—Ç—Ä–æ–µ–Ω–Ω—ã–π NGramPerReqLogitsProcessor –∏–∑ vLLM 0.11.0")
except ImportError:
    print("‚ö†Ô∏è NGramPerReqLogitsProcessor –Ω–µ –Ω–∞–π–¥–µ–Ω - –ø—Ä–æ–ø—É—Å–∫–∞–µ–º")


def load_image(image_path):
    """–ó–∞–≥—Ä—É–∑–∏—Ç—å –∏–∑–æ–±—Ä–∞–∂–µ–Ω–∏–µ —Å –∫–æ—Ä—Ä–µ–∫—Ü–∏–µ–π EXIF"""
    try:
        image = Image.open(image_path)
        corrected_image = ImageOps.exif_transpose(image)
        return corrected_image
    except Exception as e:
        print(f"‚ö†Ô∏è –û—à–∏–±–∫–∞ –∑–∞–≥—Ä—É–∑–∫–∏ –∏–∑–æ–±—Ä–∞–∂–µ–Ω–∏—è: {e}")
        return Image.open(image_path)


def generate_with_vllm(llm, image, prompt):
    """–ì–µ–Ω–µ—Ä–∞—Ü–∏—è —Å –∏—Å–ø–æ–ª—å–∑–æ–≤–∞–Ω–∏–µ–º vLLM 0.11.0"""
    
    # –ü–∞—Ä–∞–º–µ—Ç—Ä—ã —Å–µ–º–ø–ª–∏—Ä–æ–≤–∞–Ω–∏—è
    sampling_kwargs = {
        "temperature": 0.0,
        "max_tokens": 8192,
        "skip_special_tokens": False,
    }
    
    # –î–æ–±–∞–≤–ª—è–µ–º –ø–∞—Ä–∞–º–µ—Ç—Ä—ã –¥–ª—è NGram –ª–æ–≥–∏—Ç –ø—Ä–æ—Ü–µ—Å—Å–æ—Ä–∞ –µ—Å–ª–∏ –¥–æ—Å—Ç—É–ø–µ–Ω
    if NGramPerReqLogitsProcessor is not None:
        sampling_kwargs["extra_args"] = dict(
            ngram_size=30,
            window_size=90,
            whitelist_token_ids={128821, 128822},  # <td>, </td>
        )
    
    sampling_params = SamplingParams(**sampling_kwargs)
    
    # –§–æ—Ä–º–∏—Ä—É–µ–º –∑–∞–ø—Ä–æ—Å (vLLM 0.11.0 API)
    model_input = {
        "prompt": prompt,
        "multi_modal_data": {"image": image}
    }
    
    print(f"\n{'='*80}")
    print(f"üîÑ –ì–ï–ù–ï–†–ê–¶–ò–Ø (vLLM 0.11.0)")
    print(f"{'='*80}\n")
    
    start_time = time.time()
    
    # –ì–µ–Ω–µ—Ä–∞—Ü–∏—è (—Å–∏–Ω—Ö—Ä–æ–Ω–Ω—ã–π API)
    outputs = llm.generate([model_input], sampling_params)
    
    elapsed_time = time.time() - start_time
    
    # –ò–∑–≤–ª–µ–∫–∞–µ–º —Ä–µ–∑—É–ª—å—Ç–∞—Ç
    result = outputs[0].outputs[0].text
    
    print(result)
    print(f"\n\n‚è±Ô∏è –í—Ä–µ–º—è –≥–µ–Ω–µ—Ä–∞—Ü–∏–∏: {elapsed_time:.2f} —Å–µ–∫")
    
    return result


def main():
    """–û—Å–Ω–æ–≤–Ω–∞—è —Ñ—É–Ω–∫—Ü–∏—è —Ç–µ—Å—Ç–∏—Ä–æ–≤–∞–Ω–∏—è"""
    
    print(f"\n{'='*80}")
    print(f"üß™ –¢–ï–°–¢–ò–†–û–í–ê–ù–ò–ï vLLM 0.11.0 –ù–ê –°–¢–†–ê–ù–ò–¶–ï 23")
    print(f"{'='*80}\n")
    
    # –ü—É—Ç–∏
    image_path = Path("/home/budnik_an/Obligations/output/vllm_test/page_23.png")
    output_dir = Path("/home/budnik_an/Obligations/output/vllm_test")
    output_file = output_dir / "vllm_0.11_result.txt"
    
    # –ü—Ä–æ–≤–µ—Ä–∫–∞ –∏–∑–æ–±—Ä–∞–∂–µ–Ω–∏—è
    if not image_path.exists():
        print(f"‚ùå –ò–∑–æ–±—Ä–∞–∂–µ–Ω–∏–µ –Ω–µ –Ω–∞–π–¥–µ–Ω–æ: {image_path}")
        return
    
    print(f"‚úÖ –ò–∑–æ–±—Ä–∞–∂–µ–Ω–∏–µ: {image_path}")
    print(f"   –†–∞–∑–º–µ—Ä —Ñ–∞–π–ª–∞: {image_path.stat().st_size / 1024:.1f} KB")
    
    # –ó–∞–≥—Ä—É–∑–∫–∞ –∏–∑–æ–±—Ä–∞–∂–µ–Ω–∏—è
    print("\nüì• –ó–∞–≥—Ä—É–∂–∞–µ–º –∏–∑–æ–±—Ä–∞–∂–µ–Ω–∏–µ...")
    image = load_image(str(image_path)).convert('RGB')
    print(f"‚úÖ –†–∞–∑–º–µ—Ä: {image.size[0]}x{image.size[1]} –ø–∏–∫—Å–µ–ª–µ–π")
    
    # –ü—Ä–æ–º–ø—Ç ocr_simple (–ª—É—á—à–∏–π —Ä–µ–∑—É–ª—å—Ç–∞—Ç –Ω–∞ —Ç–µ—Å—Ç–∞—Ö)
    prompt = '<image>\n<|grounding|>OCR this image.'
    print(f"\nüìù –ü—Ä–æ–º–ø—Ç: ocr_simple")
    print(f"   '{prompt}'")
    
    # –ò–Ω–∏—Ü–∏–∞–ª–∏–∑–∞—Ü–∏—è vLLM 0.11.0
    print("\nüì¶ –ò–Ω–∏—Ü–∏–∞–ª–∏–∑–∞—Ü–∏—è vLLM 0.11.0...")
    print("   (–ú–æ–∂–µ—Ç –∑–∞–Ω—è—Ç—å 1-2 –º–∏–Ω—É—Ç—ã –ø—Ä–∏ –ø–µ—Ä–≤–æ–º –∑–∞–ø—É—Å–∫–µ)")
    
    # –ü–æ–¥–≥–æ—Ç–æ–≤–∫–∞ –ø–∞—Ä–∞–º–µ—Ç—Ä–æ–≤ –º–æ–¥–µ–ª–∏
    llm_kwargs = {
        "model": "deepseek-ai/DeepSeek-OCR",
        "trust_remote_code": True,
        "enable_prefix_caching": False,
        "mm_processor_cache_gb": 0,
        "gpu_memory_utilization": 0.75,
        "max_model_len": 8192,
    }
    
    # –î–æ–±–∞–≤–ª—è–µ–º –ª–æ–≥–∏—Ç –ø—Ä–æ—Ü–µ—Å—Å–æ—Ä –µ—Å–ª–∏ –¥–æ—Å—Ç—É–ø–µ–Ω
    if NGramPerReqLogitsProcessor is not None:
        llm_kwargs["logits_processors"] = [NGramPerReqLogitsProcessor]
        print("   ‚úÖ NGram –ª–æ–≥–∏—Ç –ø—Ä–æ—Ü–µ—Å—Å–æ—Ä –∞–∫—Ç–∏–≤–∏—Ä–æ–≤–∞–Ω")
    
    llm = LLM(**llm_kwargs)
    
    print("‚úÖ vLLM –¥–≤–∏–∂–æ–∫ –≥–æ—Ç–æ–≤\n")
    
    # –ì–µ–Ω–µ—Ä–∞—Ü–∏—è —Å vLLM
    result = generate_with_vllm(llm, image, prompt)
    
    # –°–æ—Ö—Ä–∞–Ω–µ–Ω–∏–µ —Ä–µ–∑—É–ª—å—Ç–∞—Ç–∞
    output_file.parent.mkdir(parents=True, exist_ok=True)
    with open(output_file, 'w', encoding='utf-8') as f:
        f.write(result)
    
    print(f"\n{'='*80}")
    print(f"‚úÖ –†–ï–ó–£–õ–¨–¢–ê–¢ –°–û–•–†–ê–ù–ï–ù: {output_file}")
    print(f"{'='*80}\n")
    
    # –°—Ç–∞—Ç–∏—Å—Ç–∏–∫–∞
    lines = result.split('\n')
    print(f"üìä –°—Ç–∞—Ç–∏—Å—Ç–∏–∫–∞:")
    print(f"   –°—Ç—Ä–æ–∫: {len(lines)}")
    print(f"   –°–∏–º–≤–æ–ª–æ–≤: {len(result)}")
    print(f"   –†–∞–∑–º–µ—Ä —Ñ–∞–π–ª–∞: {output_file.stat().st_size / 1024:.1f} KB")


if __name__ == "__main__":
    try:
        main()
    except KeyboardInterrupt:
        print("\n\n‚ö†Ô∏è –ü—Ä–µ—Ä–≤–∞–Ω–æ –ø–æ–ª—å–∑–æ–≤–∞—Ç–µ–ª–µ–º")
    except Exception as e:
        print(f"\n\n‚ùå –û–®–ò–ë–ö–ê: {e}")
        import traceback
        traceback.print_exc()

