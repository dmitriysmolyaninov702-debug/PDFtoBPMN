# DeepSeek-OCR API - –ü–æ–ª–Ω–∞—è –¥–æ–∫—É–º–µ–Ω—Ç–∞—Ü–∏—è

**–î–∞—Ç–∞:** 31 –æ–∫—Ç—è–±—Ä—è 2025  
**–ò—Å—Ç–æ—á–Ω–∏–∫:** `DeepSeek-OCR-hf/run_dpsk_ocr.py` + `config.py`  
**–í–µ—Ä—Å–∏—è –º–æ–¥–µ–ª–∏:** deepseek-ai/DeepSeek-OCR

---

## üìã –°–æ–¥–µ—Ä–∂–∞–Ω–∏–µ

1. [–ò–Ω–∏—Ü–∏–∞–ª–∏–∑–∞—Ü–∏—è –º–æ–¥–µ–ª–∏](#–∏–Ω–∏—Ü–∏–∞–ª–∏–∑–∞—Ü–∏—è-–º–æ–¥–µ–ª–∏)
2. [–ú–µ—Ç–æ–¥ model.infer()](#–º–µ—Ç–æ–¥-modelinfer)
3. [–†–µ–∂–∏–º—ã —Ä–∞–±–æ—Ç—ã](#—Ä–µ–∂–∏–º—ã-—Ä–∞–±–æ—Ç—ã)
4. [–ü—Ä–æ–º–ø—Ç—ã](#–ø—Ä–æ–º–ø—Ç—ã)
5. [–ü–∞—Ä–∞–º–µ—Ç—Ä—ã –ø—Ä–æ–∏–∑–≤–æ–¥–∏—Ç–µ–ª—å–Ω–æ—Å—Ç–∏](#–ø–∞—Ä–∞–º–µ—Ç—Ä—ã-–ø—Ä–æ–∏–∑–≤–æ–¥–∏—Ç–µ–ª—å–Ω–æ—Å—Ç–∏)
6. [–ü—Ä–∏–º–µ—Ä—ã –∏—Å–ø–æ–ª—å–∑–æ–≤–∞–Ω–∏—è](#–ø—Ä–∏–º–µ—Ä—ã-–∏—Å–ø–æ–ª—å–∑–æ–≤–∞–Ω–∏—è)

---

## üöÄ –ò–Ω–∏—Ü–∏–∞–ª–∏–∑–∞—Ü–∏—è –º–æ–¥–µ–ª–∏

### –ó–∞–≥—Ä—É–∑–∫–∞ –º–æ–¥–µ–ª–∏ —Å HuggingFace

```python
from transformers import AutoModel, AutoTokenizer
import torch
import os

# –û–ø—Ü–∏–æ–Ω–∞–ª—å–Ω–æ: –≤—ã–±–æ—Ä GPU
os.environ["CUDA_VISIBLE_DEVICES"] = '0'

model_name = 'deepseek-ai/DeepSeek-OCR'

# –ó–∞–≥—Ä—É–∑–∫–∞ tokenizer
tokenizer = AutoTokenizer.from_pretrained(
    model_name, 
    trust_remote_code=True
)

# –ó–∞–≥—Ä—É–∑–∫–∞ –º–æ–¥–µ–ª–∏
model = AutoModel.from_pretrained(
    model_name,
    _attn_implementation='flash_attention_2',  # –∏–ª–∏ 'eager' –µ—Å–ª–∏ flash-attn –Ω–µ —É—Å—Ç–∞–Ω–æ–≤–ª–µ–Ω
    trust_remote_code=True,
    use_safetensors=True,
    torch_dtype=torch.bfloat16,  # –†–µ–∫–æ–º–µ–Ω–¥—É–µ—Ç—Å—è –¥–ª—è –ø—Ä–æ–∏–∑–≤–æ–¥–∏—Ç–µ–ª—å–Ω–æ—Å—Ç–∏
    device_map="cuda"  # –ê–≤—Ç–æ–º–∞—Ç–∏—á–µ—Å–∫–∏ –∑–∞–≥—Ä—É–∂–∞–µ—Ç –Ω–∞ GPU
)
model = model.eval()
```

### –ü–∞—Ä–∞–º–µ—Ç—Ä—ã –∑–∞–≥—Ä—É–∑–∫–∏ –º–æ–¥–µ–ª–∏

| –ü–∞—Ä–∞–º–µ—Ç—Ä | –ó–Ω–∞—á–µ–Ω–∏–µ | –û–ø–∏—Å–∞–Ω–∏–µ |
|----------|----------|----------|
| `_attn_implementation` | `'flash_attention_2'` | ‚ö° –ë—ã—Å—Ç—Ä—ã–π attention (—Ç—Ä–µ–±—É–µ—Ç flash-attn) |
| | `'eager'` | Fallback (–º–µ–¥–ª–µ–Ω–Ω–µ–µ, –Ω–æ –±–µ–∑ –∑–∞–≤–∏—Å–∏–º–æ—Å—Ç–µ–π) |
| `torch_dtype` | `torch.bfloat16` | –û–ø—Ç–∏–º–∞–ª—å–Ω—ã–π –¥–ª—è RTX 5080 (—Ç–æ—á–Ω–æ—Å—Ç—å + —Å–∫–æ—Ä–æ—Å—Ç—å) |
| | `torch.float16` | –ê–ª—å—Ç–µ—Ä–Ω–∞—Ç–∏–≤–∞ (–º–æ–∂–µ—Ç –±—ã—Ç—å –º–µ–Ω–µ–µ —Å—Ç–∞–±–∏–ª—å–Ω—ã–º) |
| `device_map` | `"cuda"` | –ê–≤—Ç–æ–º–∞—Ç–∏—á–µ—Å–∫–∞—è –∑–∞–≥—Ä—É–∑–∫–∞ –Ω–∞ GPU |
| | `"cuda:0"` | –ö–æ–Ω–∫—Ä–µ—Ç–Ω—ã–π GPU |
| | `"auto"` | –ê–≤—Ç–æ–º–∞—Ç–∏—á–µ—Å–∫–∏–π –≤—ã–±–æ—Ä —É—Å—Ç—Ä–æ–π—Å—Ç–≤–∞ |
| `use_safetensors` | `True` | –ë–µ–∑–æ–ø–∞—Å–Ω—ã–π —Ñ–æ—Ä–º–∞—Ç –≤–µ—Å–æ–≤ (—Ä–µ–∫–æ–º–µ–Ω–¥—É–µ—Ç—Å—è) |
| `trust_remote_code` | `True` | **–û–ë–Ø–ó–ê–¢–ï–õ–¨–ù–û** –¥–ª—è DeepSeek-OCR |

---

## üîß –ú–µ—Ç–æ–¥ model.infer()

### –°–∏–≥–Ω–∞—Ç—É—Ä–∞ –º–µ—Ç–æ–¥–∞

```python
res = model.infer(
    tokenizer,           # –û–ë–Ø–ó–ê–¢–ï–õ–¨–ù–û
    prompt='',           # –û–ë–Ø–ó–ê–¢–ï–õ–¨–ù–û
    image_file='',       # –û–ë–Ø–ó–ê–¢–ï–õ–¨–ù–û
    output_path='',      # –û–ë–Ø–ó–ê–¢–ï–õ–¨–ù–û
    base_size=1024,      # –ü–æ —É–º–æ–ª—á–∞–Ω–∏—é: 1024
    image_size=1024,     # –ü–æ —É–º–æ–ª—á–∞–Ω–∏—é: 1024
    crop_mode=False,     # –ü–æ —É–º–æ–ª—á–∞–Ω–∏—é: False
    save_results=False,  # –ü–æ —É–º–æ–ª—á–∞–Ω–∏—é: False
    test_compress=False  # –ü–æ —É–º–æ–ª—á–∞–Ω–∏—é: False
)
```

### –ü–∞—Ä–∞–º–µ—Ç—Ä—ã

#### tokenizer (–æ–±—è–∑–∞—Ç–µ–ª—å–Ω—ã–π)
- **–¢–∏–ø:** `AutoTokenizer`
- **–û–ø–∏—Å–∞–Ω–∏–µ:** –¢–æ–∫–µ–Ω–∏–∑–∞—Ç–æ—Ä –º–æ–¥–µ–ª–∏, –∑–∞–≥—Ä—É–∂–µ–Ω–Ω—ã–π —á–µ—Ä–µ–∑ `AutoTokenizer.from_pretrained()`
- **–ü—Ä–∏–º–µ—Ä:** 
  ```python
  tokenizer = AutoTokenizer.from_pretrained('deepseek-ai/DeepSeek-OCR', trust_remote_code=True)
  ```

#### prompt (–æ–±—è–∑–∞—Ç–µ–ª—å–Ω—ã–π)
- **–¢–∏–ø:** `str`
- **–û–ø–∏—Å–∞–Ω–∏–µ:** –ò–Ω—Å—Ç—Ä—É–∫—Ü–∏—è –¥–ª—è –º–æ–¥–µ–ª–∏, –æ–ø—Ä–µ–¥–µ–ª—è—é—â–∞—è —Ç–∏–ø –æ–±—Ä–∞–±–æ—Ç–∫–∏
- **–í–∞—Ä–∏–∞–Ω—Ç—ã:** —Å–º. —Ä–∞–∑–¥–µ–ª [–ü—Ä–æ–º–ø—Ç—ã](#–ø—Ä–æ–º–ø—Ç—ã)
- **–ü—Ä–∏–º–µ—Ä:** 
  ```python
  prompt = "<image>\n<|grounding|>Convert the document to markdown."
  ```

#### image_file (–æ–±—è–∑–∞—Ç–µ–ª—å–Ω—ã–π)
- **–¢–∏–ø:** `str`
- **–û–ø–∏—Å–∞–Ω–∏–µ:** –ü—É—Ç—å –∫ –∏–∑–æ–±—Ä–∞–∂–µ–Ω–∏—é –¥–ª—è –æ–±—Ä–∞–±–æ—Ç–∫–∏
- **–ü–æ–¥–¥–µ—Ä–∂–∏–≤–∞–µ–º—ã–µ —Ñ–æ—Ä–º–∞—Ç—ã:** `.jpg`, `.jpeg`, `.png`, `.bmp`, `.tiff`
- **–ü—Ä–∏–º–µ—Ä:** 
  ```python
  image_file = '/path/to/image.png'
  ```

#### output_path (–æ–±—è–∑–∞—Ç–µ–ª—å–Ω—ã–π)
- **–¢–∏–ø:** `str`
- **–û–ø–∏—Å–∞–Ω–∏–µ:** –ü—É—Ç—å –∫ –¥–∏—Ä–µ–∫—Ç–æ—Ä–∏–∏ –¥–ª—è —Å–æ—Ö—Ä–∞–Ω–µ–Ω–∏—è —Ä–µ–∑—É–ª—å—Ç–∞—Ç–æ–≤ (–µ—Å–ª–∏ `save_results=True`)
- **–ü—Ä–∏–º–µ—Ä:** 
  ```python
  output_path = '/path/to/output/dir'
  ```

#### base_size (–æ–ø—Ü–∏–æ–Ω–∞–ª—å–Ω—ã–π, default: 1024)
- **–¢–∏–ø:** `int`
- **–û–ø–∏—Å–∞–Ω–∏–µ:** –ë–∞–∑–æ–≤—ã–π —Ä–∞–∑–º–µ—Ä –¥–ª—è –º–∞—Å—à—Ç–∞–±–∏—Ä–æ–≤–∞–Ω–∏—è –∏–∑–æ–±—Ä–∞–∂–µ–Ω–∏—è. –í–ª–∏—è–µ—Ç –Ω–∞ –∫–æ–ª–∏—á–µ—Å—Ç–≤–æ vision tokens.
- **–í–∞—Ä–∏–∞–Ω—Ç—ã:** `512`, `640`, `1024`, `1280`, `1536`
- **–†–µ–∫–æ–º–µ–Ω–¥–∞—Ü–∏–∏:**
  - `512` (Tiny) - –ø—Ä–æ—Å—Ç—ã–µ —Å—Ç—Ä–∞–Ω–∏—Ü—ã, 64 vision tokens
  - `640` (Small) - —Å—Ä–µ–¥–Ω–∏–µ —Å—Ç—Ä–∞–Ω–∏—Ü—ã, 100 vision tokens
  - `1024` (Base) - —Å—Ç–∞–Ω–¥–∞—Ä—Ç, 256 vision tokens ‚≠ê
  - `1280` (Large) - –ø–ª–æ—Ç–Ω—ã–µ —Å—Ç—Ä–∞–Ω–∏—Ü—ã, 400 vision tokens
  - `1536` (Extra Large) - –æ—á–µ–Ω—å –¥–µ—Ç–∞–ª—å–Ω—ã–µ, 576 vision tokens
- **–ü—Ä–∏–º–µ—Ä:** 
  ```python
  base_size = 1024  # Base mode
  ```

#### image_size (–æ–ø—Ü–∏–æ–Ω–∞–ª—å–Ω—ã–π, default: 1024)
- **–¢–∏–ø:** `int`
- **–û–ø–∏—Å–∞–Ω–∏–µ:** –¶–µ–ª–µ–≤–æ–π —Ä–∞–∑–º–µ—Ä –∏–∑–æ–±—Ä–∞–∂–µ–Ω–∏—è –¥–ª—è –æ–±—Ä–∞–±–æ—Ç–∫–∏. –í —Ä–µ–∂–∏–º–µ `crop_mode=False` –¥–æ–ª–∂–µ–Ω –±—ã—Ç—å —Ä–∞–≤–µ–Ω `base_size`.
- **–í–∞—Ä–∏–∞–Ω—Ç—ã:** –û–±—ã—á–Ω–æ —Å–æ–≤–ø–∞–¥–∞–µ—Ç —Å `base_size`, –∫—Ä–æ–º–µ Gundam mode
- **–†–µ–∫–æ–º–µ–Ω–¥–∞—Ü–∏–∏:**
  - **Base mode:** `image_size = base_size` (–Ω–∞–ø—Ä–∏–º–µ—Ä, 1024 = 1024)
  - **Gundam mode:** `image_size < base_size` (–Ω–∞–ø—Ä–∏–º–µ—Ä, 1024 base, 640 image)
- **–ü—Ä–∏–º–µ—Ä:** 
  ```python
  image_size = 1024  # –î–ª—è Base mode
  ```

#### crop_mode (–æ–ø—Ü–∏–æ–Ω–∞–ª—å–Ω—ã–π, default: False)
- **–¢–∏–ø:** `bool`
- **–û–ø–∏—Å–∞–Ω–∏–µ:** –†–µ–∂–∏–º —Ä–∞–∑–±–∏–µ–Ω–∏—è –∏–∑–æ–±—Ä–∞–∂–µ–Ω–∏—è –Ω–∞ —á–∞—Å—Ç–∏ (tiling)
- **–í–∞—Ä–∏–∞–Ω—Ç—ã:**
  - `False` - Base/Large mode (–µ–¥–∏–Ω–æ–µ –∏–∑–æ–±—Ä–∞–∂–µ–Ω–∏–µ)
  - `True` - Gundam mode (—Ä–∞–∑–±–∏–µ–Ω–∏–µ –Ω–∞ 2-9 —á–∞—Å—Ç–µ–π)
- **–ò—Å–ø–æ–ª—å–∑–æ–≤–∞–Ω–∏–µ:**
  - `False` - –¥–ª—è –æ–±—ã—á–Ω—ã—Ö –¥–æ–∫—É–º–µ–Ω—Ç–æ–≤ (A4, –∫–Ω–∏–≥–∏)
  - `True` - –¥–ª—è –≥–∞–∑–µ—Ç, –ø–æ—Å—Ç–µ—Ä–æ–≤, –ø–ª–æ—Ç–Ω—ã—Ö —Å—Ç—Ä–∞–Ω–∏—Ü
- **–í–∞–∂–Ω–æ:** –ü—Ä–∏ `crop_mode=True` —Ç–∞–∫–∂–µ —É—Å—Ç–∞–Ω–æ–≤–∏—Ç–µ `image_size` –º–µ–Ω—å—à–µ `base_size`
- **–ü—Ä–∏–º–µ—Ä:** 
  ```python
  crop_mode = False  # Base mode
  ```

#### save_results (–æ–ø—Ü–∏–æ–Ω–∞–ª—å–Ω—ã–π, default: False)
- **–¢–∏–ø:** `bool`
- **–û–ø–∏—Å–∞–Ω–∏–µ:** –°–æ—Ö—Ä–∞–Ω—è—Ç—å –ª–∏ —Ä–µ–∑—É–ª—å—Ç–∞—Ç—ã –≤ —Ñ–∞–π–ª—ã
- **–í–∞—Ä–∏–∞–Ω—Ç—ã:**
  - `False` - —Ä–µ–∑—É–ª—å—Ç–∞—Ç —Ç–æ–ª—å–∫–æ –≤ return value (—Ä–µ–∫–æ–º–µ–Ω–¥—É–µ—Ç—Å—è –¥–ª—è API)
  - `True` - —Å–æ—Ö—Ä–∞–Ω—è–µ—Ç markdown –≤ `output_path`
- **–ü—Ä–∏–º–µ—Ä:** 
  ```python
  save_results = False  # –ù–µ —Å–æ—Ö—Ä–∞–Ω—è—Ç—å —Ñ–∞–π–ª—ã
  ```

#### test_compress (–æ–ø—Ü–∏–æ–Ω–∞–ª—å–Ω—ã–π, default: False)
- **–¢–∏–ø:** `bool`
- **–û–ø–∏—Å–∞–Ω–∏–µ:** –¢–µ—Å—Ç–∏—Ä–æ–≤–∞—Ç—å —Å–∂–∞—Ç–∏–µ —Ç–æ–∫–µ–Ω–æ–≤ (–¥–ª—è –æ—Ç–ª–∞–¥–∫–∏)
- **–í–∞—Ä–∏–∞–Ω—Ç—ã:**
  - `False` - –æ–±—ã—á–Ω–∞—è —Ä–∞–±–æ—Ç–∞
  - `True` - –≤—ã–≤–æ–¥–∏—Ç —Å—Ç–∞—Ç–∏—Å—Ç–∏–∫—É —Å–∂–∞—Ç–∏—è –≤ stdout
- **–ò—Å–ø–æ–ª—å–∑–æ–≤–∞–Ω–∏–µ:** –¢–æ–ª—å–∫–æ –¥–ª—è —Ä–∞–∑—Ä–∞–±–æ—Ç–∫–∏ –∏ –æ—Ç–ª–∞–¥–∫–∏
- **–ü—Ä–∏–º–µ—Ä:** 
  ```python
  test_compress = False  # –û—Ç–∫–ª—é—á–µ–Ω–æ –¥–ª—è production
  ```

### –í–æ–∑–≤—Ä–∞—â–∞–µ–º–æ–µ –∑–Ω–∞—á–µ–Ω–∏–µ

‚ö†Ô∏è **–í–ê–ñ–ù–û:** `model.infer()` **–ø–µ—á–∞—Ç–∞–µ—Ç —Ä–µ–∑—É–ª—å—Ç–∞—Ç –≤ stdout** –∏ –≤–æ–∑–≤—Ä–∞—â–∞–µ—Ç `None`!

```python
res = model.infer(...)  # res = None

# –†–µ–∑—É–ª—å—Ç–∞—Ç –ø–µ—á–∞—Ç–∞–µ—Ç—Å—è –≤ stdout:
# =====================
# BASE:  torch.Size([1, 256, 1280])
# NO PATCHES
# =====================
# <|ref|>text<|/ref|><|det|>[[x0, y0, x1, y1]]<|/det|>
# –†–∞—Å–ø–æ–∑–Ω–∞–Ω–Ω—ã–π —Ç–µ–∫—Å—Ç
```

**–î–ª—è –∑–∞—Ö–≤–∞—Ç–∞ —Ä–µ–∑—É–ª—å—Ç–∞—Ç–∞:**

```python
import sys
from io import StringIO

old_stdout = sys.stdout
sys.stdout = captured_output = StringIO()

try:
    res = model.infer(tokenizer, prompt=prompt, ...)
finally:
    sys.stdout = old_stdout
    result = captured_output.getvalue()

print(result)  # –¢–µ–ø–µ—Ä—å —É –≤–∞—Å –µ—Å—Ç—å —Ç–µ–∫—Å—Ç —Ä–µ–∑—É–ª—å—Ç–∞—Ç–∞
```

---

## üé® –†–µ–∂–∏–º—ã —Ä–∞–±–æ—Ç—ã

### –¢–∞–±–ª–∏—Ü–∞ —Ä–µ–∂–∏–º–æ–≤

| –†–µ–∂–∏–º | base_size | image_size | crop_mode | Vision Tokens | –ü—Ä–∏–º–µ–Ω–µ–Ω–∏–µ | VRAM |
|-------|-----------|------------|-----------|---------------|------------|------|
| **Tiny** | 512 | 512 | False | 64 | –ü—Ä–æ—Å—Ç—ã–µ —Å—Ç—Ä–∞–Ω–∏—Ü—ã | ~4GB |
| **Small** | 640 | 640 | False | 100 | –°—Ä–µ–¥–Ω–∏–µ —Å—Ç—Ä–∞–Ω–∏—Ü—ã | ~6GB |
| **Base** | 1024 | 1024 | False | 256 | ‚≠ê –°—Ç–∞–Ω–¥–∞—Ä—Ç (—Ä–µ–∫–æ–º–µ–Ω–¥—É–µ—Ç—Å—è) | ~8GB |
| **Large** | 1280 | 1280 | False | 400 | –ü–ª–æ—Ç–Ω—ã–µ —Å—Ç—Ä–∞–Ω–∏—Ü—ã | ~12GB |
| **Extra Large** | 1536 | 1536 | False | 576 | –û—á–µ–Ω—å –¥–µ—Ç–∞–ª—å–Ω—ã–µ | ~16GB |
| **Gundam** | 1024 | 640 | True | Dynamic (2-9 crops) | –ì–∞–∑–µ—Ç—ã, –ø–æ—Å—Ç–µ—Ä—ã | ~12GB |

### –†–µ–∫–æ–º–µ–Ω–¥–∞—Ü–∏–∏ –ø–æ –≤—ã–±–æ—Ä—É —Ä–µ–∂–∏–º–∞

**–î–ª—è –¥–æ–∫—É–º–µ–Ω—Ç–æ–≤ (A4, –∫–Ω–∏–≥–∏, –æ—Ç—á–µ—Ç—ã):**
```python
# Base mode - –æ–ø—Ç–∏–º–∞–ª—å–Ω—ã–π –±–∞–ª–∞–Ω—Å
base_size = 1024
image_size = 1024
crop_mode = False
```

**–î–ª—è –º–µ–ª–∫–æ–≥–æ —Ç–µ–∫—Å—Ç–∞ / —Ç–∞–±–ª–∏—Ü:**
```python
# Large mode - –±–æ–ª—å—à–µ –¥–µ—Ç–∞–ª–µ–π
base_size = 1280
image_size = 1280
crop_mode = False
```

**–î–ª—è –≥–∞–∑–µ—Ç / –ø–æ—Å—Ç–µ—Ä–æ–≤:**
```python
# Gundam mode - dynamic tiling
base_size = 1024
image_size = 640
crop_mode = True
```

**–î–ª—è –±—ã—Å—Ç—Ä–æ–π –æ–±—Ä–∞–±–æ—Ç–∫–∏:**
```python
# Small mode - –±—ã—Å—Ç—Ä–µ–µ, –Ω–æ –º–µ–Ω–µ–µ —Ç–æ—á–Ω—ã–π
base_size = 640
image_size = 640
crop_mode = False
```

---

## üí¨ –ü—Ä–æ–º–ø—Ç—ã

### –û—Ñ–∏—Ü–∏–∞–ª—å–Ω—ã–µ –ø—Ä–æ–º–ø—Ç—ã

| # | –ü—Ä–æ–º–ø—Ç | –û–ø–∏—Å–∞–Ω–∏–µ | –ò—Å–ø–æ–ª—å–∑–æ–≤–∞–Ω–∏–µ |
|---|--------|----------|---------------|
| 1 | `<image>\n<|grounding|>Convert the document to markdown.` | ‚≠ê –î–æ–∫—É–º–µ–Ω—Ç ‚Üí Markdown —Å bbox | –î–æ–∫—É–º–µ–Ω—Ç—ã, –æ—Ç—á–µ—Ç—ã |
| 2 | `<image>\nFree OCR.` | –°–≤–æ–±–æ–¥–Ω—ã–π OCR –±–µ–∑ —Å—Ç—Ä—É–∫—Ç—É—Ä—ã | –ë—ã—Å—Ç—Ä–æ–µ –∏–∑–≤–ª–µ—á–µ–Ω–∏–µ —Ç–µ–∫—Å—Ç–∞ |
| 3 | `<image>\n<|grounding|>OCR this image.` | OCR —Å bbox –∫–æ–æ—Ä–¥–∏–Ω–∞—Ç–∞–º–∏ | –ü—Ä–æ–∏–∑–≤–æ–ª—å–Ω—ã–µ –∏–∑–æ–±—Ä–∞–∂–µ–Ω–∏—è |
| 4 | `<image>\nParse the figure.` | –ü–∞—Ä—Å–∏–Ω–≥ –≥—Ä–∞—Ñ–∏–∫–∞/–¥–∏–∞–≥—Ä–∞–º–º—ã | ‚ùå –ù–ï OCR! –û–ø–∏—Å—ã–≤–∞–µ—Ç –¥–∏–∞–≥—Ä–∞–º–º—É |
| 5 | `<image>\nDescribe this image in detail.` | –î–µ—Ç–∞–ª—å–Ω–æ–µ –æ–ø–∏—Å–∞–Ω–∏–µ | ‚ùå –ù–ï OCR! –ì–µ–Ω–µ—Ä–∏—Ä—É–µ—Ç –æ–ø–∏—Å–∞–Ω–∏–µ |
| 6 | `<image>\nLocate <\|ref\|>—Ç–µ–∫—Å—Ç<\|/ref\|> in the image.` | –ü–æ–∏—Å–∫ –∫–æ–Ω–∫—Ä–µ—Ç–Ω–æ–≥–æ —Ç–µ–∫—Å—Ç–∞ | –õ–æ–∫–∞–ª–∏–∑–∞—Ü–∏—è —ç–ª–µ–º–µ–Ω—Ç–æ–≤ |

### –†–µ–∂–∏–º `<|grounding|>` - —á—Ç–æ —ç—Ç–æ?

**`<|grounding|>` = –¥–æ–±–∞–≤–ª—è–µ—Ç BBox –∫–æ–æ—Ä–¥–∏–Ω–∞—Ç—ã –∫ —Ä–∞—Å–ø–æ–∑–Ω–∞–Ω–Ω–æ–º—É —Ç–µ–∫—Å—Ç—É**

**–ë–µ–∑ `<|grounding|>`:**
```
–≠—Ç–æ —Ç–µ–∫—Å—Ç –¥–æ–∫—É–º–µ–Ω—Ç–∞.
```

**–° `<|grounding|>`:**
```
<|ref|>text<|/ref|><|det|>[[106, 170, 763, 190]]<|/det|>
–≠—Ç–æ —Ç–µ–∫—Å—Ç –¥–æ–∫—É–º–µ–Ω—Ç–∞.
```

–ì–¥–µ:
- `<|ref|>text<|/ref|>` - —Ç–∏–ø —ç–ª–µ–º–µ–Ω—Ç–∞ (text, image, table)
- `<|det|>[[x0, y0, x1, y1]]<|/det|>` - –∫–æ–æ—Ä–¥–∏–Ω–∞—Ç—ã bounding box

### –ö–∞—Å—Ç–æ–º–Ω—ã–µ –ø—Ä–æ–º–ø—Ç—ã –¥–ª—è BPMN (–ø—Ä–æ—Ç–µ—Å—Ç–∏—Ä–æ–≤–∞–Ω–Ω—ã–µ)

‚ö†Ô∏è **–ù–∏ –æ–¥–∏–Ω –Ω–µ –∑–∞—Å—Ç–∞–≤–∏–ª –º–æ–¥–µ–ª—å –∏–∑–≤–ª–µ—á—å —Ç–µ–∫—Å—Ç –∏–∑ BPMN –¥–∏–∞–≥—Ä–∞–º–º!**

```python
# –ü–æ–ø—ã—Ç–∫–∞ 1
prompt = "<image>\n<|grounding|>Extract ALL text from this image, including text inside diagram shapes and boxes."

# –ü–æ–ø—ã—Ç–∫–∞ 2
prompt = "<image>\n<|grounding|>OCR this diagram. Extract text from all shapes, labels, and annotations."

# –ü–æ–ø—ã—Ç–∫–∞ 3
prompt = "<image>\n<|grounding|>Convert the BPMN diagram to markdown. Include all text from shapes, gateways, and events."
```

**–†–µ–∑—É–ª—å—Ç–∞—Ç:** –ú–æ–¥–µ–ª—å –≤–∏–¥–∏—Ç –¥–∏–∞–≥—Ä–∞–º–º—É –∫–∞–∫ `<|ref|>image<|/ref|>` –∏ –Ω–µ –∏–∑–≤–ª–µ–∫–∞–µ—Ç —Ç–µ–∫—Å—Ç –∏–∑–Ω—É—Ç—Ä–∏.

---

## ‚öôÔ∏è –ü–∞—Ä–∞–º–µ—Ç—Ä—ã –ø—Ä–æ–∏–∑–≤–æ–¥–∏—Ç–µ–ª—å–Ω–æ—Å—Ç–∏

### –í config.py

```python
# Concurrent –∑–∞–ø—Ä–æ—Å—ã
MAX_CONCURRENCY = 50  # –î–ª—è 16GB VRAM
# –£–º–µ–Ω—å—à–∏—Ç–µ –¥–æ 20-30 –µ—Å–ª–∏ CUDA OOM
# –£–≤–µ–ª–∏—á—å—Ç–µ –¥–æ 100 –µ—Å–ª–∏ –µ—Å—Ç—å –∑–∞–ø–∞—Å VRAM

# –í–æ—Ä–∫–µ—Ä—ã –ø—Ä–µ–¥–æ–±—Ä–∞–±–æ—Ç–∫–∏ –∏–∑–æ–±—Ä–∞–∂–µ–Ω–∏–π
NUM_WORKERS = 32  # –û–ø—Ç–∏–º–∞–ª—å–Ω–æ = –∫–æ–ª–∏—á–µ—Å—Ç–≤–æ CPU cores

# –û—Ç–ª–∞–¥–∫–∞
PRINT_NUM_VIS_TOKENS = False  # True –¥–ª—è –æ—Ç–ª–∞–¥–∫–∏
SKIP_REPEAT = True  # –ü—Ä–æ–ø—É—Å–∫–∞—Ç—å –ø–æ–≤—Ç–æ—Ä—ã
```

### –ü—Ä–æ–∏–∑–≤–æ–¥–∏—Ç–µ–ª—å–Ω–æ—Å—Ç—å –Ω–∞ RTX 5080 (16GB)

| –†–µ–∂–∏–º | –í—Ä–µ–º—è (—Å–µ–∫) | Vision Tokens | –ö–∞—á–µ—Å—Ç–≤–æ |
|-------|-------------|---------------|----------|
| Tiny | ~0.5 | 64 | –ù–∏–∑–∫–æ–µ |
| Small | ~0.8 | 100 | –°—Ä–µ–¥–Ω–µ–µ |
| Base | ~1.5-2.0 | 256 | –í—ã—Å–æ–∫–æ–µ ‚≠ê |
| Large | ~2.5-3.0 | 400 | –û—á–µ–Ω—å –≤—ã—Å–æ–∫–æ–µ |
| Gundam | ~5-10 | 128-576 | –í—ã—Å–æ–∫–æ–µ (–¥–ª—è –≥–∞–∑–µ—Ç) |

**–° flash-attention vs –±–µ–∑:**
- –° flash-attn: ~1.5-2x –±—ã—Å—Ç—Ä–µ–µ
- –ë–µ–∑ (eager): —Å—Ç–∞–±–∏–ª—å–Ω–æ, –Ω–æ –º–µ–¥–ª–µ–Ω–Ω–µ–µ

---

## üìù –ü—Ä–∏–º–µ—Ä—ã –∏—Å–ø–æ–ª—å–∑–æ–≤–∞–Ω–∏—è

### –ü—Ä–∏–º–µ—Ä 1: –ë–∞–∑–æ–≤–æ–µ –∏—Å–ø–æ–ª—å–∑–æ–≤–∞–Ω–∏–µ (Base mode)

```python
from transformers import AutoModel, AutoTokenizer
import torch

# –ó–∞–≥—Ä—É–∑–∫–∞
model_name = 'deepseek-ai/DeepSeek-OCR'
tokenizer = AutoTokenizer.from_pretrained(model_name, trust_remote_code=True)
model = AutoModel.from_pretrained(
    model_name,
    _attn_implementation='flash_attention_2',
    trust_remote_code=True,
    use_safetensors=True,
    torch_dtype=torch.bfloat16,
    device_map="cuda"
)
model = model.eval()

# –û–±—Ä–∞–±–æ—Ç–∫–∞
prompt = "<image>\n<|grounding|>Convert the document to markdown."
image_file = 'document.png'
output_path = './output'

# –ó–∞—Ö–≤–∞—Ç stdout
import sys
from io import StringIO

old_stdout = sys.stdout
sys.stdout = captured_output = StringIO()

try:
    res = model.infer(
        tokenizer,
        prompt=prompt,
        image_file=image_file,
        output_path=output_path,
        base_size=1024,
        image_size=1024,
        crop_mode=False,
        save_results=False,
        test_compress=False
    )
finally:
    sys.stdout = old_stdout
    result = captured_output.getvalue()

print(result)
```

### –ü—Ä–∏–º–µ—Ä 2: Large mode –¥–ª—è –¥–µ—Ç–∞–ª—å–Ω–æ–≥–æ —Ä–∞—Å–ø–æ–∑–Ω–∞–≤–∞–Ω–∏—è

```python
# Large mode - –±–æ–ª—å—à–µ vision tokens
res = model.infer(
    tokenizer,
    prompt="<image>\n<|grounding|>Convert the document to markdown.",
    image_file='detailed_document.png',
    output_path='./output',
    base_size=1280,  # Large
    image_size=1280,
    crop_mode=False,
    save_results=False,
    test_compress=False
)
```

### –ü—Ä–∏–º–µ—Ä 3: Gundam mode –¥–ª—è –≥–∞–∑–µ—Ç

```python
# Gundam mode - dynamic tiling
res = model.infer(
    tokenizer,
    prompt="<image>\n<|grounding|>Convert the document to markdown.",
    image_file='newspaper.png',
    output_path='./output',
    base_size=1024,
    image_size=640,  # –ú–µ–Ω—å—à–µ base_size!
    crop_mode=True,  # –í–∫–ª—é—á–µ–Ω tiling
    save_results=False,
    test_compress=False
)
```

### –ü—Ä–∏–º–µ—Ä 4: –ë—ã—Å—Ç—Ä–æ–µ –∏–∑–≤–ª–µ—á–µ–Ω–∏–µ —Ç–µ–∫—Å—Ç–∞ (–±–µ–∑ bbox)

```python
# Free OCR - –±—ã—Å—Ç—Ä—ã–π, –±–µ–∑ –∫–æ–æ—Ä–¥–∏–Ω–∞—Ç
res = model.infer(
    tokenizer,
    prompt="<image>\nFree OCR.",
    image_file='simple_text.png',
    output_path='./output',
    base_size=640,  # Small mode –¥–ª—è —Å–∫–æ—Ä–æ—Å—Ç–∏
    image_size=640,
    crop_mode=False,
    save_results=False,
    test_compress=False
)
```

---

## üîç –ü–∞—Ä—Å–∏–Ω–≥ —Ä–µ–∑—É–ª—å—Ç–∞—Ç–æ–≤

### –§–æ—Ä–º–∞—Ç –≤—ã–≤–æ–¥–∞ —Å `<|grounding|>`

```
=====================
BASE:  torch.Size([1, 256, 1280])
NO PATCHES
=====================

<|ref|>text<|/ref|><|det|>[[80, 119, 510, 135]]<|/det|>
–ó–∞–≥–æ–ª–æ–≤–æ–∫ –¥–æ–∫—É–º–µ–Ω—Ç–∞

<|ref|>text<|/ref|><|det|>[[106, 170, 763, 190]]<|/det|>
–ü–∞—Ä–∞–≥—Ä–∞—Ñ —Ç–µ–∫—Å—Ç–∞

<|ref|>table<|/ref|><|det|>[[100, 300, 700, 500]]<|/det|>
| –ö–æ–ª–æ–Ω–∫–∞ 1 | –ö–æ–ª–æ–Ω–∫–∞ 2 |
|-----------|-----------|
| –î–∞–Ω–Ω—ã–µ    | –î–∞–Ω–Ω—ã–µ    |

<|ref|>image<|/ref|><|det|>[[327, 309, 667, 536]]<|/det|>
```

### –ü–∞—Ä—Å–∏–Ω–≥ –≤ Python

```python
import re

def parse_deepseek_output(output):
    blocks = []
    lines = output.split('\n')
    
    for i, line in enumerate(lines):
        if '<|ref|>' in line:
            # –ò–∑–≤–ª–µ–∫–∞–µ–º —Ç–∏–ø
            block_type = line.split('<|ref|>')[1].split('<|/ref|>')[0]
            
            # –ò–∑–≤–ª–µ–∫–∞–µ–º bbox
            bbox = None
            if '<|det|>' in line:
                det_str = line.split('<|det|>')[1].split('<|/det|>')[0]
                import ast
                bbox_list = ast.literal_eval(det_str)
                if bbox_list:
                    bbox = bbox_list[0]
            
            # –ò–∑–≤–ª–µ–∫–∞–µ–º —Ç–µ–∫—Å—Ç (–Ω–∞ —Å–ª–µ–¥—É—é—â–∏—Ö —Å—Ç—Ä–æ–∫–∞—Ö)
            content = []
            j = i + 1
            while j < len(lines) and not lines[j].startswith('<|'):
                if lines[j].strip():
                    content.append(lines[j].strip())
                j += 1
            
            blocks.append({
                'type': block_type,
                'bbox': bbox,
                'content': '\n'.join(content)
            })
    
    return blocks
```

---

## ‚ö†Ô∏è –ò–∑–≤–µ—Å—Ç–Ω—ã–µ –æ–≥—Ä–∞–Ω–∏—á–µ–Ω–∏—è

### 1. BPMN –¥–∏–∞–≥—Ä–∞–º–º—ã –ù–ï —Ä–∞—Å–ø–æ–∑–Ω–∞—é—Ç—Å—è

**–ü—Ä–æ–±–ª–µ–º–∞:** –ú–æ–¥–µ–ª—å –≤–∏–¥–∏—Ç –¥–∏–∞–≥—Ä–∞–º–º—É –∫–∞–∫ –µ–¥–∏–Ω—ã–π `<|ref|>image<|/ref|>` –±–ª–æ–∫ –∏ –Ω–µ –∏–∑–≤–ª–µ–∫–∞–µ—Ç —Ç–µ–∫—Å—Ç –∏–∑–Ω—É—Ç—Ä–∏ —Ñ–∏–≥—É—Ä.

**–†–µ—à–µ–Ω–∏–µ:** Fine-tuning –Ω–∞ BPMN –¥–∞—Ç–∞—Å–µ—Ç–µ –∏–ª–∏ –∏—Å–ø–æ–ª—å–∑–æ–≤–∞–Ω–∏–µ –∞–ª—å—Ç–µ—Ä–Ω–∞—Ç–∏–≤–Ω—ã—Ö –∏–Ω—Å—Ç—Ä—É–º–µ–Ω—Ç–æ–≤.

### 2. –ü—Ä–æ–º–ø—Ç—ã `parse_figure` –∏ `describe` - —ç—Ç–æ –ù–ï OCR

**–ü—Ä–æ–±–ª–µ–º–∞:** –û–Ω–∏ –≥–µ–Ω–µ—Ä–∏—Ä—É—é—Ç –æ–ø–∏—Å–∞–Ω–∏–µ –∏–∑–æ–±—Ä–∞–∂–µ–Ω–∏—è, –∞ –Ω–µ —Ä–∞—Å–ø–æ–∑–Ω–∞—é—Ç —Ç–µ–∫—Å—Ç.

**–†–µ—à–µ–Ω–∏–µ:** –ò—Å–ø–æ–ª—å–∑—É–π—Ç–µ –ø—Ä–æ–º–ø—Ç `<|grounding|>Convert the document to markdown.`

### 3. model.infer() –≤–æ–∑–≤—Ä–∞—â–∞–µ—Ç None

**–ü—Ä–æ–±–ª–µ–º–∞:** –†–µ–∑—É–ª—å—Ç–∞—Ç –ø–µ—á–∞—Ç–∞–µ—Ç—Å—è –≤ stdout, –∞ –Ω–µ –≤–æ–∑–≤—Ä–∞—â–∞–µ—Ç—Å—è.

**–†–µ—à–µ–Ω–∏–µ:** –ó–∞—Ö–≤–∞—Ç—ã–≤–∞–π—Ç–µ stdout —á–µ—Ä–µ–∑ `StringIO` (—Å–º. –ø—Ä–∏–º–µ—Ä—ã –≤—ã—à–µ).

### 4. –ö–æ–æ—Ä–¥–∏–Ω–∞—Ç—ã –≤ –ø–∏–∫—Å–µ–ª—è—Ö –æ—Ä–∏–≥–∏–Ω–∞–ª—å–Ω–æ–≥–æ –∏–∑–æ–±—Ä–∞–∂–µ–Ω–∏—è

**–ü—Ä–æ–±–ª–µ–º–∞:** BBox –∫–æ–æ—Ä–¥–∏–Ω–∞—Ç—ã —Å–æ–æ—Ç–≤–µ—Ç—Å—Ç–≤—É—é—Ç –º–∞—Å—à—Ç–∞–±–∏—Ä–æ–≤–∞–Ω–Ω–æ–º—É –∏–∑–æ–±—Ä–∞–∂–µ–Ω–∏—é, –∞ –Ω–µ –æ—Ä–∏–≥–∏–Ω–∞–ª—É.

**–†–µ—à–µ–Ω–∏–µ:** –ü–µ—Ä–µ—Å—á–∏—Ç—ã–≤–∞–π—Ç–µ –∫–æ–æ—Ä–¥–∏–Ω–∞—Ç—ã —Å —É—á–µ—Ç–æ–º –º–∞—Å—à—Ç–∞–±–∏—Ä–æ–≤–∞–Ω–∏—è.

---

## üìö –î–æ–ø–æ–ª–Ω–∏—Ç–µ–ª—å–Ω—ã–µ —Ä–µ—Å—É—Ä—Å—ã

- **–û—Ñ–∏—Ü–∏–∞–ª—å–Ω—ã–π —Ä–µ–ø–æ–∑–∏—Ç–æ—Ä–∏–π:** https://github.com/deepseek-ai/DeepSeek-OCR
- **HuggingFace Hub:** https://huggingface.co/deepseek-ai/DeepSeek-OCR
- **–û–±–ª–∞—á–Ω—ã–π API:** https://www.deepseek-ocr.ai/docs
- **Paper:** (—Å—Å—ã–ª–∫–∞ –Ω–∞ arXiv, –∫–æ–≥–¥–∞ –æ–ø—É–±–ª–∏–∫—É—é—Ç)

---

**–ê–≤—Ç–æ—Ä –¥–æ–∫—É–º–µ–Ω—Ç–∞—Ü–∏–∏:** BPMN Automation Team  
**–í–µ—Ä—Å–∏—è:** 1.0  
**–î–∞—Ç–∞:** 31 –æ–∫—Ç—è–±—Ä—è 2025

