"""
DeepSeek-OCR Wrapper –¥–ª—è –∏–Ω—Ç–µ–≥—Ä–∞—Ü–∏–∏ —Å –º–∏–∫—Ä–æ—Å–µ—Ä–≤–∏—Å–æ–º

–û–±–µ—Ä—Ç–∫–∞ –¥–ª—è —Ä–∞–±–æ—Ç—ã —Å DeepSeek-OCR —á–µ—Ä–µ–∑ vLLM –≤ –Ω–∞—à–µ–º –º–∏–∫—Ä–æ—Å–µ—Ä–≤–∏—Å–µ.
–£–ø—Ä–æ—â–∞–µ—Ç –≤–∑–∞–∏–º–æ–¥–µ–π—Å—Ç–≤–∏–µ –º–µ–∂–¥—É FastAPI –∏ DeepSeek-OCR.
"""

import sys
from pathlib import Path
from typing import Dict, Any, List, Optional
import base64
import io
from PIL import Image

# –î–æ–±–∞–≤–ª—è–µ–º –ø—É—Ç—å –∫ DeepSeek-OCR
DEEPSEEK_DIR = Path(__file__).parent.parent.parent / "DeepSeek-OCR" / "DeepSeek-OCR-master" / "DeepSeek-OCR-vllm"
sys.path.insert(0, str(DEEPSEEK_DIR))

try:
    from vllm import LLM, SamplingParams
    from process.ngram_norepeat import NGramPerReqLogitsProcessor
    import config as deepseek_config
    DEEPSEEK_AVAILABLE = True
except ImportError as e:
    DEEPSEEK_AVAILABLE = False
    print(f"‚ö†Ô∏è  DeepSeek-OCR –Ω–µ –¥–æ—Å—Ç—É–ø–µ–Ω: {e}")


class DeepSeekOCRWrapper:
    """
    –û–±–µ—Ä—Ç–∫–∞ –¥–ª—è DeepSeek-OCR
    
    –£–ø—Ä–æ—â–∞–µ—Ç —Ä–∞–±–æ—Ç—É —Å –º–æ–¥–µ–ª—å—é —á–µ—Ä–µ–∑ vLLM, —É–ø—Ä–∞–≤–ª—è–µ—Ç —Ä–µ–∂–∏–º–∞–º–∏ —Ä–∞–±–æ—Ç—ã,
    –∏ —Ñ–æ—Ä–º–∞—Ç–∏—Ä—É–µ—Ç —Ä–µ–∑—É–ª—å—Ç–∞—Ç—ã –¥–ª—è API.
    """
    
    # –ö–æ–Ω—Ñ–∏–≥—É—Ä–∞—Ü–∏—è —Ä–µ–∂–∏–º–æ–≤
    MODES = {
        "Tiny": {"base_size": 512, "image_size": 512, "vision_tokens": 64},
        "Small": {"base_size": 640, "image_size": 640, "vision_tokens": 100},
        "Base": {"base_size": 1024, "image_size": 1024, "vision_tokens": 256},
        "Large": {"base_size": 1280, "image_size": 1280, "vision_tokens": 400},
        "Gundam": {"base_size": 1024, "image_size": 640, "vision_tokens": None}  # Dynamic
    }
    
    # –ü—Ä–æ–º–ø—Ç—ã –¥–ª—è —Ä–∞–∑–Ω—ã—Ö –∑–∞–¥–∞—á
    PROMPTS = {
        "document": '<image>\n<|grounding|>Convert the document to markdown.',
        "free_ocr": '<image>\nFree OCR.',
        "image_ocr": '<image>\n<|grounding|>OCR this image.',
        "figure": '<image>\nParse the figure.',
        "describe": '<image>\nDescribe this image in detail.',
    }
    
    def __init__(self, model_path: str = "deepseek-ai/DeepSeek-OCR"):
        """
        –ò–Ω–∏—Ü–∏–∞–ª–∏–∑–∞—Ü–∏—è DeepSeek-OCR
        
        Args:
            model_path: –ü—É—Ç—å –∫ –º–æ–¥–µ–ª–∏ (HuggingFace –∏–ª–∏ –ª–æ–∫–∞–ª—å–Ω—ã–π)
        """
        self.model_path = model_path
        self.llm = None
        self.available = DEEPSEEK_AVAILABLE
        
        if DEEPSEEK_AVAILABLE:
            self._load_model()
        else:
            print("‚ö†Ô∏è  Wrapper –≤ stub-—Ä–µ–∂–∏–º–µ")
    
    def _load_model(self):
        """–ó–∞–≥—Ä—É–∑–∫–∞ –º–æ–¥–µ–ª–∏ —á–µ—Ä–µ–∑ vLLM"""
        try:
            print(f"üîÑ –ó–∞–≥—Ä—É–∑–∫–∞ DeepSeek-OCR: {self.model_path}")
            
            # –ü–∞—Ä–∞–º–µ—Ç—Ä—ã vLLM –¥–ª—è DeepSeek-OCR
            self.llm = LLM(
                model=self.model_path,
                trust_remote_code=True,  # –û–±—è–∑–∞—Ç–µ–ª—å–Ω–æ –¥–ª—è DeepSeek-OCR
                gpu_memory_utilization=0.9,
                max_model_len=4096,
                dtype="bfloat16",  # –û–ø—Ç–∏–º–∞–ª—å–Ω–æ –¥–ª—è OCR
                disable_log_stats=False,
            )
            
            print("‚úÖ DeepSeek-OCR –∑–∞–≥—Ä—É–∂–µ–Ω")
            self.available = True
        
        except Exception as e:
            print(f"‚ùå –û—à–∏–±–∫–∞ –∑–∞–≥—Ä—É–∑–∫–∏ –º–æ–¥–µ–ª–∏: {e}")
            self.available = False
            raise
    
    def process_image(
        self,
        image_bytes: bytes,
        mode: str = "Base",
        prompt: Optional[str] = None,
        task_type: str = "document"
    ) -> Dict[str, Any]:
        """
        –û–±—Ä–∞–±–æ—Ç–∫–∞ –∏–∑–æ–±—Ä–∞–∂–µ–Ω–∏—è —á–µ—Ä–µ–∑ DeepSeek-OCR
        
        Args:
            image_bytes: –ë–∞–π—Ç—ã –∏–∑–æ–±—Ä–∞–∂–µ–Ω–∏—è (PNG, JPG)
            mode: –†–µ–∂–∏–º —Ä–∞–±–æ—Ç—ã (Tiny/Small/Base/Large/Gundam)
            prompt: –ö–∞—Å—Ç–æ–º–Ω—ã–π –ø—Ä–æ–º–ø—Ç (–µ—Å–ª–∏ None - –∏—Å–ø–æ–ª—å–∑—É–µ—Ç—Å—è –ø–æ task_type)
            task_type: –¢–∏–ø –∑–∞–¥–∞—á–∏ (document/free_ocr/image_ocr/figure/describe)
        
        Returns:
            Dict —Å —Ä–µ–∑—É–ª—å—Ç–∞—Ç–∞–º–∏ OCR:
                - markdown: str - —Ä–µ–∑—É–ª—å—Ç–∞—Ç –≤ Markdown
                - blocks: List[Dict] - —Å—Ç—Ä—É–∫—Ç—É—Ä–∏—Ä–æ–≤–∞–Ω–Ω—ã–µ –±–ª–æ–∫–∏
                - vision_tokens: int - –∫–æ–ª–∏—á–µ—Å—Ç–≤–æ vision —Ç–æ–∫–µ–Ω–æ–≤
                - text_tokens: int - –∫–æ–ª–∏—á–µ—Å—Ç–≤–æ —Ç–µ–∫—Å—Ç–æ–≤—ã—Ö —Ç–æ–∫–µ–Ω–æ–≤
                - mode: str - –∏—Å–ø–æ–ª—å–∑–æ–≤–∞–Ω–Ω—ã–π —Ä–µ–∂–∏–º
        """
        if not self.available or not self.llm:
            return self._stub_response(image_bytes, mode)
        
        try:
            # –ó–∞–≥—Ä—É–∑–∫–∞ –∏–∑–æ–±—Ä–∞–∂–µ–Ω–∏—è
            image = Image.open(io.BytesIO(image_bytes))
            
            # –í—ã–±–æ—Ä –ø—Ä–æ–º–ø—Ç–∞
            if prompt is None:
                prompt = self.PROMPTS.get(task_type, self.PROMPTS["document"])
            
            # –ù–∞—Å—Ç—Ä–æ–π–∫–∞ sampling —Å NGram logits processor –¥–ª—è —Å—Ç–∞–±–∏–ª—å–Ω–æ—Å—Ç–∏
            sampling_params = SamplingParams(
                temperature=0.0,  # –î–µ—Ç–µ—Ä–º–∏–Ω–∏—Ä–æ–≤–∞–Ω–Ω—ã–π –≤—ã–≤–æ–¥ –¥–ª—è OCR
                max_tokens=2048,
                top_p=1.0,
                # NGramPerReqLogitsProcessor –¥–æ–±–∞–≤–ª—è–µ—Ç—Å—è —á–µ—Ä–µ–∑ vLLM
                logits_processors=[
                    NGramPerReqLogitsProcessor(
                        ngram_size=3,
                        window_size=20,
                        # whitelist –º–æ–∂–Ω–æ –¥–æ–±–∞–≤–∏—Ç—å –µ—Å–ª–∏ –Ω—É–∂–Ω–æ
                    )
                ] if DEEPSEEK_AVAILABLE else []
            )
            
            # –ì–µ–Ω–µ—Ä–∞—Ü–∏—è (—Å–∏–Ω—Ö—Ä–æ–Ω–Ω–∞—è –¥–ª—è –ø—Ä–æ—Å—Ç–æ—Ç—ã)
            # –í –ø—Ä–æ–¥–∞–∫—à–µ–Ω–µ –º–æ–∂–Ω–æ –∏—Å–ø–æ–ª—å–∑–æ–≤–∞—Ç—å async –≤–µ—Ä—Å–∏—é
            outputs = self.llm.generate(
                prompts=[prompt],
                sampling_params=sampling_params,
                # –ò–∑–æ–±—Ä–∞–∂–µ–Ω–∏–µ –ø–µ—Ä–µ–¥–∞–µ—Ç—Å—è —á–µ—Ä–µ–∑ multimodal inputs
                # –¢–æ—á–Ω—ã–π API –∑–∞–≤–∏—Å–∏—Ç –æ—Ç –≤–µ—Ä—Å–∏–∏ vLLM –∏ DeepSeek-OCR
            )
            
            # –ò–∑–≤–ª–µ—á–µ–Ω–∏–µ —Ä–µ–∑—É–ª—å—Ç–∞—Ç–∞
            generated_text = outputs[0].outputs[0].text
            token_ids = outputs[0].outputs[0].token_ids
            
            # –ü–∞—Ä—Å–∏–Ω–≥ Markdown –≤ –±–ª–æ–∫–∏
            blocks = self._parse_markdown(generated_text)
            
            # –ü–æ–¥—Å—á–µ—Ç —Ç–æ–∫–µ–Ω–æ–≤
            mode_config = self.MODES.get(mode, self.MODES["Base"])
            vision_tokens = mode_config["vision_tokens"] or 256
            
            return {
                "markdown": generated_text,
                "blocks": blocks,
                "vision_tokens": vision_tokens,
                "text_tokens": len(token_ids),
                "mode": mode
            }
        
        except Exception as e:
            print(f"‚ùå –û—à–∏–±–∫–∞ OCR: {e}")
            # Fallback –Ω–∞ stub
            return self._stub_response(image_bytes, mode)
    
    def _parse_markdown(self, markdown: str) -> List[Dict[str, Any]]:
        """
        –ü–∞—Ä—Å–∏–Ω–≥ Markdown –≤ —Å—Ç—Ä—É–∫—Ç—É—Ä–∏—Ä–æ–≤–∞–Ω–Ω—ã–µ –±–ª–æ–∫–∏
        
        Args:
            markdown: Markdown —Ç–µ–∫—Å—Ç
        
        Returns:
            –°–ø–∏—Å–æ–∫ –±–ª–æ–∫–æ–≤ —Å –º–µ—Ç–∞–¥–∞–Ω–Ω—ã–º–∏
        """
        blocks = []
        lines = markdown.split('\n')
        
        for i, line in enumerate(lines):
            if not line.strip():
                continue
            
            # –û–ø—Ä–µ–¥–µ–ª—è–µ–º —Ç–∏–ø –±–ª–æ–∫–∞
            if line.startswith('#'):
                block_type = "heading"
                level = len(line) - len(line.lstrip('#'))
            elif line.startswith('- ') or line.startswith('* ') or line.startswith('+ '):
                block_type = "list_item"
                level = 1
            elif line.startswith('|'):
                block_type = "table_row"
                level = 1
            elif line.startswith('```'):
                block_type = "code_block"
                level = 1
            elif line.startswith('>'):
                block_type = "quote"
                level = 1
            else:
                block_type = "paragraph"
                level = 1
            
            blocks.append({
                "id": f"block_{i}",
                "type": block_type,
                "content": line.strip(),
                "bbox": [0, 0, 0, 0],  # TODO: –∏–∑–≤–ª–µ–∫–∞—Ç—å –∏–∑ grounding –µ—Å–ª–∏ –¥–æ—Å—Ç—É–ø–Ω–æ
                "confidence": 0.95,
                "metadata": {
                    "level": level,
                    "line_number": i + 1
                }
            })
        
        return blocks
    
    def _stub_response(self, image_bytes: bytes, mode: str) -> Dict[str, Any]:
        """
        –ó–∞–≥–ª—É—à–∫–∞ –∫–æ–≥–¥–∞ –º–æ–¥–µ–ª—å –Ω–µ–¥–æ—Å—Ç—É–ø–Ω–∞
        
        Args:
            image_bytes: –ë–∞–π—Ç—ã –∏–∑–æ–±—Ä–∞–∂–µ–Ω–∏—è
            mode: –†–µ–∂–∏–º
        
        Returns:
            Stub response
        """
        try:
            image = Image.open(io.BytesIO(image_bytes))
            width, height = image.size
        except:
            width, height = 0, 0
        
        stub_markdown = f"""# Stub OCR Response

**Mode:** {mode}  
**Image Size:** {width}x{height}

‚ö†Ô∏è This is a placeholder response. The DeepSeek-OCR model is not available.

To enable OCR:
1. Ensure vLLM is installed
2. Ensure DeepSeek-OCR is properly configured
3. Check logs for errors

See `docs/DeepSeek_OCR_Setup.md` for setup instructions.
"""
        
        blocks = [{
            "id": "stub_block_0",
            "type": "paragraph",
            "content": "Stub OCR content",
            "bbox": [0, 0, float(width), float(height)],
            "confidence": 1.0,
            "metadata": {"stub": True}
        }]
        
        mode_config = self.MODES.get(mode, self.MODES["Base"])
        
        return {
            "markdown": stub_markdown,
            "blocks": blocks,
            "vision_tokens": mode_config["vision_tokens"] or 256,
            "text_tokens": len(stub_markdown.split()),
            "mode": mode
        }
    
    def health_check(self) -> Dict[str, Any]:
        """
        –ü—Ä–æ–≤–µ—Ä–∫–∞ –∑–¥–æ—Ä–æ–≤—å—è –æ–±–µ—Ä—Ç–∫–∏
        
        Returns:
            –°—Ç–∞—Ç—É—Å –∏ –∏–Ω—Ñ–æ—Ä–º–∞—Ü–∏—è –æ –º–æ–¥–µ–ª–∏
        """
        return {
            "available": self.available,
            "model_loaded": self.llm is not None,
            "model_path": self.model_path,
            "modes": list(self.MODES.keys()),
            "deepseek_available": DEEPSEEK_AVAILABLE
        }


# –ì–ª–æ–±–∞–ª—å–Ω—ã–π —ç–∫–∑–µ–º–ø–ª—è—Ä (singleton)
_wrapper_instance: Optional[DeepSeekOCRWrapper] = None

def get_deepseek_wrapper() -> DeepSeekOCRWrapper:
    """
    –ü–æ–ª—É—á–∏—Ç—å –≥–ª–æ–±–∞–ª—å–Ω—ã–π —ç–∫–∑–µ–º–ø–ª—è—Ä DeepSeek wrapper (singleton)
    
    Returns:
        DeepSeekOCRWrapper instance
    """
    global _wrapper_instance
    
    if _wrapper_instance is None:
        _wrapper_instance = DeepSeekOCRWrapper()
    
    return _wrapper_instance

